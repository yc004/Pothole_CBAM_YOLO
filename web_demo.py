import sys
import os
import asyncio

# ä¿®å¤ Windows ä¸‹ä¸­æ–‡ä¹±ç é—®é¢˜
if sys.platform.startswith('win'):
    os.system('chcp 65001 >nul')
    # ä¿®å¤ Windows ä¸‹ asyncio æŠ¥é”™ (WinError 10054)
    asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
    
    if hasattr(sys.stdout, 'reconfigure'):
        sys.stdout.reconfigure(encoding='utf-8')
    if hasattr(sys.stderr, 'reconfigure'):
        sys.stderr.reconfigure(encoding='utf-8')

import gradio as gr
import cv2
from ultralytics import YOLO
from PIL import Image
import numpy as np
import subprocess
import shutil

# ================= é…ç½® =================
# æƒé‡è·¯å¾„
MODEL_PATH_BASELINE = "Pothole_Baseline_Project/exp_baseline/weights/best.pt"
MODEL_PATH_CBAM = "Pothole_CBAM_Project/exp_cbam/weights/best.pt"

print(f"â³ æ­£åœ¨åŠ è½½æ¨¡å‹...")
try:
    print(f"   - åŠ è½½åŸºçº¿æ¨¡å‹: {MODEL_PATH_BASELINE}")
    model_baseline = YOLO(MODEL_PATH_BASELINE)
    print(f"   - åŠ è½½æ”¹è¿›æ¨¡å‹ (CBAM): {MODEL_PATH_CBAM}")
    model_cbam = YOLO(MODEL_PATH_CBAM)
    print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼")
except Exception as e:
    print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    print("è¯·æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®ï¼Œæˆ–è€…æ˜¯å¦å·²ç»è¿è¡Œäº† train_pothole.py è¿›è¡Œè®­ç»ƒã€‚")
    sys.exit(1)

def detect_pothole(image):
    """
    æ‰§è¡Œè·¯é¢å‘æ´¼æ£€æµ‹ (å¯¹æ¯”æ¨¡å¼)
    :param image: è¾“å…¥å›¾ç‰‡ (PIL.Image)
    :return: åŸºçº¿ç»“æœå›¾, æ”¹è¿›ç»“æœå›¾, æ£€æµ‹ä¿¡æ¯æ–‡æœ¬
    """
    if image is None:
        return None, None, "è¯·å…ˆä¸Šä¼ å›¾ç‰‡"

    # 1. åŸºçº¿æ¨¡å‹æ¨ç†
    results_baseline = model_baseline.predict(image, conf=0.25)
    res_base = results_baseline[0]
    plot_base_bgr = res_base.plot()
    plot_base_rgb = plot_base_bgr[..., ::-1] # BGR to RGB
    count_base = len(res_base.boxes)

    # 2. æ”¹è¿›æ¨¡å‹æ¨ç†
    results_cbam = model_cbam.predict(image, conf=0.25)
    res_cbam = results_cbam[0]
    plot_cbam_bgr = res_cbam.plot()
    plot_cbam_rgb = plot_cbam_bgr[..., ::-1] # BGR to RGB
    count_cbam = len(res_cbam.boxes)
    
    info = (f"âœ… æ£€æµ‹å®Œæˆï¼\n"
            f"ğŸ”¹ åŸºçº¿æ¨¡å‹æ£€æµ‹åˆ°: {count_base} ä¸ªç›®æ ‡\n"
            f"ğŸ”¸ æ”¹è¿›æ¨¡å‹æ£€æµ‹åˆ°: {count_cbam} ä¸ªç›®æ ‡")
    
    return plot_base_rgb, plot_cbam_rgb, info

def detect_video(video_path):
    """
    å¤„ç†è§†é¢‘æ–‡ä»¶ (å¯¹æ¯”æ¨¡å¼ - åˆå¹¶æ˜¾ç¤º)
    """
    if video_path is None:
        return None, "è¯·ä¸Šä¼ è§†é¢‘"
        
    cap = cv2.VideoCapture(video_path)
    
    # ä¸´æ—¶æ–‡ä»¶è·¯å¾„
    temp_raw_combined = "temp_raw_combined.mp4"
    output_path_combined = "output_video_combined.mp4"
    
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    
    # è¾“å‡ºè§†é¢‘å®½åº¦ä¸ºä¸¤å€ (å·¦å³å¹¶æ’)
    new_width = width * 2
    
    # OpenCV å†™å…¥ä¸´æ—¶æ–‡ä»¶
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(temp_raw_combined, fourcc, fps, (new_width, height))
    
    frame_count = 0
    total_detections_base = 0
    total_detections_cbam = 0
    
    print("ğŸ”„ æ­£åœ¨é€å¸§å¤„ç†è§†é¢‘ (åˆå¹¶æ¨¡å¼)...")
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        
        # 1. Baseline Inference
        results_base = model_baseline.predict(frame, conf=0.25, verbose=False)
        annotated_frame_base = results_base[0].plot()
        total_detections_base += len(results_base[0].boxes)
        
        # æ·»åŠ æ ‡ç­¾
        cv2.putText(annotated_frame_base, "Baseline", (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 
                    1.2, (0, 0, 255), 3, cv2.LINE_AA)

        # 2. CBAM Inference
        results_cbam = model_cbam.predict(frame, conf=0.25, verbose=False)
        annotated_frame_cbam = results_cbam[0].plot()
        total_detections_cbam += len(results_cbam[0].boxes)
        
        # æ·»åŠ æ ‡ç­¾
        cv2.putText(annotated_frame_cbam, "CBAM (Improved)", (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 
                    1.2, (0, 255, 0), 3, cv2.LINE_AA)
        
        # 3. åˆå¹¶ç”»é¢
        combined_frame = np.hstack((annotated_frame_base, annotated_frame_cbam))
        out.write(combined_frame)
        
        frame_count += 1
        if frame_count % 10 == 0:
            print(f"   å·²å¤„ç† {frame_count} å¸§...", end="\r")
        
    cap.release()
    out.release()
    print(f"\nâœ… è§†é¢‘æ¨ç†å®Œæˆï¼Œå…± {frame_count} å¸§ã€‚")
    
    # è½¬ç å‡½æ•°
    def transcode(input_path, output_path):
        if shutil.which("ffmpeg"):
            try:
                print(f"ğŸ”„ æ­£åœ¨è½¬ç ...")
                subprocess.run([
                    "ffmpeg", "-y", 
                    "-i", input_path, 
                    "-c:v", "h264_mf", # Windows ç¡¬ä»¶åŠ é€Ÿ
                    "-b:v", "5M",      
                    "-rate_control", "cbr", 
                    "-f", "mp4", 
                    output_path
                ], check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
                return output_path, True
            except Exception as e:
                print(f"âš ï¸ è½¬ç å¤±è´¥: {e}")
                return input_path, False
        else:
            return input_path, False

    # æ‰§è¡Œè½¬ç 
    final_video, is_transcoded = transcode(temp_raw_combined, output_path_combined)
    
    msg_status = "è½¬ç æˆåŠŸ" if is_transcoded else "æœªè½¬ç (å¯èƒ½æ— æ³•é¢„è§ˆ)"
    if not shutil.which("ffmpeg"):
         msg_status = "æœªå®‰è£…FFmpegï¼Œæ— æ³•é¢„è§ˆï¼Œè¯·ä¸‹è½½è§‚çœ‹"

    info = (f"âœ… è§†é¢‘å¤„ç†å®Œæˆï¼\n"
            f"å…±å¤„ç† {frame_count} å¸§ã€‚\n"
            f"ğŸ”¹ åŸºçº¿æ¨¡å‹ç´¯è®¡æ£€æµ‹: {total_detections_base} æ¬¡\n"
            f"ğŸ”¸ æ”¹è¿›æ¨¡å‹ç´¯è®¡æ£€æµ‹: {total_detections_cbam} æ¬¡\n"
            f"â„¹ï¸ çŠ¶æ€: {msg_status}")

    return final_video, info

# ================= æ„å»ºç•Œé¢ =================
with gr.Blocks(title="è·¯é¢å‘æ´¼æ£€æµ‹æ¨¡å‹å¯¹æ¯”ç³»ç»Ÿ") as demo:
    gr.Markdown("# ğŸ›£ï¸ è·¯é¢å‘æ´¼æ£€æµ‹ç³»ç»Ÿ - æ¨¡å‹æ•ˆæœå¯¹æ¯”")
    gr.Markdown("æœ¬ç³»ç»ŸåŒæ—¶å±•ç¤º **Baseline (åŸºçº¿æ¨¡å‹)** ä¸ **CBAM (æ”¹è¿›æ¨¡å‹)** çš„æ£€æµ‹ç»“æœï¼Œä»¥ä¾¿ç›´è§‚å¯¹æ¯”æ€§èƒ½å·®å¼‚ã€‚")
    
    with gr.Tabs():
        with gr.TabItem("ğŸ“· å›¾ç‰‡å¯¹æ¯”æ£€æµ‹"):
            gr.Markdown("ä¸Šä¼ è·¯é¢ç…§ç‰‡ï¼Œç³»ç»Ÿå°†åˆ†åˆ«ä½¿ç”¨åŸºçº¿æ¨¡å‹å’Œæ”¹è¿›æ¨¡å‹è¿›è¡Œæ£€æµ‹ã€‚")
            with gr.Row():
                with gr.Column(scale=1):
                    input_img = gr.Image(type="pil", label="ä¸Šä¼ åŸå§‹å›¾ç‰‡")
                    run_btn = gr.Button("å¼€å§‹å¯¹æ¯”æ£€æµ‹", variant="primary")
                
                with gr.Column(scale=2):
                    with gr.Row():
                        output_base = gr.Image(type="numpy", label="åŸºçº¿æ¨¡å‹ (Baseline) ç»“æœ")
                        output_cbam = gr.Image(type="numpy", label="æ”¹è¿›æ¨¡å‹ (CBAM) ç»“æœ")
                    output_text = gr.Textbox(label="æ£€æµ‹ç»Ÿè®¡ä¿¡æ¯")
                    
            run_btn.click(fn=detect_pothole, inputs=input_img, outputs=[output_base, output_cbam, output_text])
            
            gr.Examples(
                examples=["datasets/New_pothole_detection.v2i.yolov8/test/images/1_jpg.rf.a9cc87ae30331b83ba2e75fddcf1ebd5.jpg"],
                inputs=input_img
            )
            
        with gr.TabItem("ğŸ¥ è§†é¢‘å¯¹æ¯”æ£€æµ‹"):
            gr.Markdown("ä¸Šä¼ è·¯é¢è§†é¢‘ï¼Œç³»ç»Ÿå°†ç”Ÿæˆ **Baseline (å·¦)** å’Œ **CBAM (å³)** çš„å¹¶æ’å¯¹æ¯”è§†é¢‘ï¼Œæ–¹ä¾¿é€å¸§æ¯”å¯¹æ•ˆæœã€‚")
            with gr.Row():
                with gr.Column(scale=1):
                    input_video = gr.Video(label="ä¸Šä¼ è§†é¢‘")
                    video_btn = gr.Button("å¼€å§‹å¯¹æ¯”å¤„ç†", variant="primary")
                
                with gr.Column(scale=2):
                    output_video_combined = gr.Video(label="å¯¹æ¯”ç»“æœ (å·¦: Baseline | å³: CBAM)")
                    video_info = gr.Textbox(label="å¤„ç†ä¿¡æ¯")
            
            video_btn.click(fn=detect_video, inputs=input_video, outputs=[output_video_combined, video_info])

if __name__ == "__main__":
    print("ğŸš€ å¯åŠ¨ Web æœåŠ¡...")
    # launch(inbrowser=True) ä¼šè‡ªåŠ¨æ‰“å¼€æµè§ˆå™¨
    demo.launch(inbrowser=True)
